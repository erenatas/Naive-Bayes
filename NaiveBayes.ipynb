{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libs\n",
    "#conda install -c anaconda pandas \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from __future__ import division\n",
    "\n",
    "\n",
    "#from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get CSV\n",
    "columnNames=['Sex','Length','Diameter','Height','WholeWeight','ShuckedWeight','VisceraWeight','ShellWeight','classlabel'] \n",
    "train = pd.read_csv(\"abalone_dataset.txt\",delimiter=\"\\t\", names=columnNames, header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_x_given_y(x, mean_y, variance_y):\n",
    "    # Input the arguments into a probability density function\n",
    "    exponent = math.exp(-(math.pow(x - mean_y, 2) / (2 * variance_y)))\n",
    "    return (1 / (math.sqrt(2 * math.pi * variance_y))) * exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(result):\n",
    "    true = 0\n",
    "    total = len(result)\n",
    "    cmExpected = []\n",
    "    cmPredicted = []\n",
    "    for i in range(len(result)):\n",
    "        if result[i][0] == result[i][1]:\n",
    "            true += 1\n",
    "        cmExpected.append(result[i][1])\n",
    "        cmPredicted.append(result[i][0])\n",
    "    misclassification = total - true;\n",
    "    cm = confusion_matrix(cmExpected, cmPredicted)\n",
    "    return cm, total, true, misclassification, true/len(result)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hotEncodeSex(data, test):\n",
    "    # Hot Encode Sex for Data and Test\n",
    "    sexHotEncodeData = pd.get_dummies(data['Sex'])\n",
    "    data = data.drop('Sex', axis = 1)\n",
    "    data = data.join(sexHotEncodeData)\n",
    "    sexHotEncodeTest = pd.get_dummies(test['Sex'])\n",
    "    test = test.drop('Sex', axis = 1)\n",
    "    test = test.join(sexHotEncodeTest)\n",
    "    \n",
    "    return data, test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preCalculations(data):\n",
    "    numOf1 = data['classlabel'][data['classlabel'] == 1].count()\n",
    "    numOf2 = data['classlabel'][data['classlabel'] == 2].count()\n",
    "    numOf3 = data['classlabel'][data['classlabel'] == 3].count()\n",
    "    \n",
    "    totalClassLabel = data['classlabel'].count()\n",
    "    \n",
    "    prior1 = numOf1/totalClassLabel\n",
    "    prior2 = numOf1/totalClassLabel\n",
    "    prior3 = numOf1/totalClassLabel\n",
    "    \n",
    "    dataMean     = data.groupby('classlabel').mean()\n",
    "    dataVariance = data.groupby('classlabel').var()\n",
    "    \n",
    "    return prior1, prior2, prior3, dataMean, dataVariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes(attributes, data, test, expectedTest):\n",
    "    data, test = hotEncodeSex(data, test)\n",
    "    prior1, prior2, prior3, dataMean, dataVariance = preCalculations(data)\n",
    "    priors = [prior1, prior2, prior3]\n",
    "    classLabelTypes = [1, 2, 3]\n",
    "    output = []\n",
    "    \n",
    "    for i in range(len(test)):\n",
    "        expectedResult = expectedTest['classlabel'].iloc[i]\n",
    "        maxOfClassLabels = []\n",
    "        for classLabelType in range(len(classLabelTypes)):\n",
    "            probabilityOfClassLabelType = priors[classLabelType]\n",
    "            for attribute in range(len(attributes)):\n",
    "                    mean_y = dataMean[attributes[attribute]][dataVariance.index == classLabelType + 1].values[0]\n",
    "                    variance_y = dataVariance[attributes[attribute]][dataVariance.index == classLabelTypes[classLabelType]].values[0]\n",
    "                    probabilityOfClassLabelType = probabilityOfClassLabelType * p_x_given_y(test[attributes[attribute]].iloc[i], mean_y, variance_y) \n",
    "            maxOfClassLabels.append(probabilityOfClassLabelType)\n",
    "        output.append([maxOfClassLabels.index(max(maxOfClassLabels)) + 1,expectedResult])\n",
    "    accuracy(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation for Cases\n",
    "train = shuffle(train)\n",
    "case1Data = train.iloc[:100, [0,1,2,8]]\n",
    "case1Test = train.iloc[101:, [0,1,2]]\n",
    "case1ExpectedTest = train.iloc[101:, [0,1,2,8]]\n",
    "case2Data = train.iloc[:1000, [0,1,2,8]]\n",
    "case2Test = train.iloc[1001:, [0,1,2]]\n",
    "case2ExpectedTest = train.iloc[1001:, [0,1,2,8]]\n",
    "case3Data = train.iloc[:2000, [0,1,2,8]]\n",
    "case3Test = train.iloc[2001:, [0,1,2]]\n",
    "case3ExpectedTest = train.iloc[2001:, [0,1,2,8]]\n",
    "case4Data = train.iloc[:100, :]\n",
    "case4Test = train.iloc[101:, :8]\n",
    "case4ExpectedTest = train.iloc[101:, :]\n",
    "case5Data = train.iloc[:1000, :]\n",
    "case5Test = train.iloc[1001:, :8]\n",
    "case5ExpectedTest = train.iloc[1001:, :]\n",
    "case6Data = train.iloc[:2000, :]\n",
    "case6Test = train.iloc[2001:, :8]\n",
    "case6ExpectedTest = train.iloc[2001:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "usedFeaturesType1 = ['F', 'M', 'I', 'Length', 'Diameter']\n",
    "usedFeaturesType2 = ['F', 'M', 'I', 'Length', 'Diameter', 'Height','WholeWeight','ShuckedWeight','VisceraWeight','ShellWeight']\n",
    "result = naiveBayes(usedFeaturesType1, case1Data, case1Test, case1ExpectedTest)\n",
    "result2 = naiveBayes(usedFeaturesType1, case2Data, case2Test, case2ExpectedTest)\n",
    "result3 = naiveBayes(usedFeaturesType1, case3Data, case3Test, case3ExpectedTest)\n",
    "result4 = naiveBayes(usedFeaturesType2, case4Data, case4Test, case4ExpectedTest)\n",
    "result5 = naiveBayes(usedFeaturesType2, case5Data, case5Test, case5ExpectedTest)\n",
    "result6 = naiveBayes(usedFeaturesType2, case6Data, case6Test, case6ExpectedTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
